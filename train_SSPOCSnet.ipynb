{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from networks_model import *\n",
    "from data_loader import *\n",
    "from error_functions import *\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import multi_gpu_model\n",
    "import time\n",
    "from layer_custom import *\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}\n",
    "\n",
    "opt['train_path'] = '/media/hd3/sylar/simu_data/calculated'\n",
    "opt['train_img1_path'] = ['/msk_arr/msk']\n",
    "opt['train_img2_path'] = ['/phs_total/phs']\n",
    "opt['train_label_path'] = ['/qsm/qsm']\n",
    "\n",
    "opt['reso'] = (0.45,0.45,1.0)\n",
    "opt['patch_size'] = (64,64,64)\n",
    "\n",
    "opt['rad'] = [5,3,1]\n",
    "opt['ker'] = []\n",
    "opt['ker'] = multi_smv_gen(opt)  # inital smv generation for multiple radias\n",
    "opt['d'] = dipole_kernel(opt)    # inital dipole kernel generation\n",
    "\n",
    "opt['lbd1'] = 0.1\n",
    "opt['iter'] = 5\n",
    "opt['thr'] = 0.05\n",
    "opt['batch_size'] = 2\n",
    "opt['channels'] = len(opt['rad'])+1\n",
    "opt['img_shape'] = opt['patch_size'] + (opt['channels'],)\n",
    "opt['in_shape'] = opt['patch_size'] + (1,)\n",
    "opt['is_patch'] = True\n",
    "opt['is_aug'] = True\n",
    "\n",
    "opt['model_restored'] = False\n",
    "opt['model_restored_epoch'] = 196\n",
    "opt['model_total_epoch'] = 300\n",
    "opt['model_save_interval'] = 1\n",
    "\n",
    "opt['learning_rate'] = 2e-4\n",
    "opt['beta_1'] = 0.9\n",
    "opt['beta_2'] = 0.99\n",
    "opt['loss'] = nrmse\n",
    "opt['display_nums'] = [10,20,30]\n",
    "opt['c_iter'] = 5 # conjugate gradient iteration number\n",
    "\n",
    "opt['model_save_path'] = '/home/maii_station_1/Desktop/codes/SS-POCSnet/modelss_saved' \n",
    "opt['checkpoint_path'] = opt['model_save_path']+\"/cp{epoch}\"\n",
    "\n",
    "if not os.path.exists(opt['model_save_path']):\n",
    "    os.makedirs(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "if not opt['model_restored']:\n",
    "    index = list(range(1,15030))\n",
    "    random.shuffle(index)\n",
    "    opt['train_index'] = index[0:15000]\n",
    "    opt['test_index'] = index[15000:15030]  \n",
    "    np.save(opt['model_save_path'] + '/train_index8.npy', opt['train_index'])\n",
    "    np.save(opt['model_save_path'] + '/test_index2.npy', opt['test_index'])\n",
    "else:\n",
    "    np.save(opt['model_save_path'] + '/train_index8.npy', opt['train_index'])\n",
    "    np.save(opt['model_save_path'] + '/test_index2.npy', opt['test_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt['train_data'] = Data_loaders(opt)\n",
    "x1_train, x2_train, y_train = opt['train_data'].next([1],opt)\n",
    "print(opt['train_data'].data_size)\n",
    "\n",
    "'''\n",
    "data preview\n",
    "'''\n",
    "plt_center(x1_train, x2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "smv, l = smv_lpf_array(opt)\n",
    "model = {}\n",
    "\n",
    "model['joint'] = joint_model(smv,opt)\n",
    "model['optimizer'] = Adam(opt['learning_rate'], opt['beta_1'], opt['beta_2'])\n",
    "\n",
    "model['joint'].compile(optimizer = model['optimizer'],\n",
    "                     loss = [opt['loss'],opt['loss']],\n",
    "                     loss_weights = [0.5, 0.5],\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "if opt['model_restored'] == True:\n",
    "    model['vnet'].load_weights(opt['checkpoint_path'].format(epoch = opt['model_restored_epoch']))\n",
    "    start_epoch = opt['model_restored_epoch']\n",
    "else:\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr_train_im = opt['train_data'].data_size\n",
    "nr_im_per_epoch = int(np.ceil(nr_train_im / opt['batch_size']) * opt['batch_size'])\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start Time:\" + str(start_time))\n",
    "\n",
    "avg_epoch_cost = []\n",
    "print('-----Start Training-----')\n",
    "for epoch in range(start_epoch, opt['model_total_epoch']):\n",
    " \n",
    "    order = np.concatenate((np.random.permutation(nr_train_im),\n",
    "                                         np.random.randint(nr_train_im, size=nr_im_per_epoch - nr_train_im)))\n",
    "    avg_img_cost = []\n",
    "    for block_i in range(1, nr_im_per_epoch+1, opt['batch_size']):\n",
    "        index = order[block_i:block_i+opt['batch_size']]\n",
    "        x1_train, x2_train, y_train = opt['train_data'].next(index, opt)\n",
    "\n",
    "        # Training\n",
    "        x_in = np.concatenate((x1_train, x2_train),axis=-1)\n",
    "        history = model['joint'].train_on_batch(x_in, [y_train,y_train] )\n",
    "        [y_pred1, y_pred2] = model['joint'].predict(x_in)\n",
    "        m_loss1 = history[0]\n",
    "        m_loss2 = history[1]\n",
    "        m_loss3 = history[2]\n",
    "        norm_loss = np.linalg.norm(y_pred1-y_train)/np.linalg.norm(y_train)\n",
    "        avg_img_cost.append(m_loss1)\n",
    "        if block_i % (30 * opt['batch_size'])==1:\n",
    "            # Plot the progress\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [Model loss: %f-%f-%f ; nrmse: %f]\" % (epoch, opt['model_total_epoch'],\n",
    "                                                                block_i, nr_train_im,\n",
    "                                                                m_loss1,m_loss2,m_loss3, norm_loss))\n",
    "            display_slice(3,opt['display_nums'], y_pred1,y_pred2, y_train)\n",
    "    avg_epoch_cost.append(np.mean(avg_img_cost)) \n",
    "                                \n",
    "    print(\"Epoch:\", '%04d' % (epoch), \"Training_cost=\", \"{:.5f}\".format(avg_epoch_cost[-1]))\n",
    "    display_error(range(start_epoch,epoch+1),avg_epoch_cost)\n",
    "\n",
    "    # If at save interval => save models\n",
    "    if epoch % opt['model_save_interval'] == 0:\n",
    "        model['vnet'].save_weights(opt['checkpoint_path'].format(epoch=epoch))\n",
    "            \n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Total Time:\" + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
